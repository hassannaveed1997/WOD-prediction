{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, logging, argparse\n",
    "import pickle, yaml\n",
    "\n",
    "import wod_predictor\n",
    "from wod_predictor.data_loader import DataLoader\n",
    "from wod_predictor.splitter import DataSplitter\n",
    "from wod_predictor.preprocessor import DataPreprocessor \n",
    "from wod_predictor.modeling import RandomForestModel\n",
    "from wod_predictor.hyperparam_search.tuner import HyperparamTuner, ParamRange\n",
    "from wod_predictor.hyperparam_search import helpers\n",
    "from wod_predictor.hyperparam_search.objectives import model_only_objective\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'configs/random_forest_model_only.yml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with the default setting defined in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted height to height in imperial units\n",
      "Converted weight to weight in imperial units\n",
      "Converted height to height in imperial units\n",
      "Converted weight to weight in imperial units\n",
      "Converted height to height in imperial units\n",
      "Converted weight to weight in imperial units\n"
     ]
    }
   ],
   "source": [
    "# Data split and preprocessing\n",
    "train, val, test = helpers.load_train_val_test_data()\n",
    "preprocessor = helpers.fit_preprocessor(\n",
    "    train, preprocessor_args=config[\"preprocessing\"]\n",
    ")\n",
    "train_processed = preprocessor.transform(train)\n",
    "val_processed = preprocessor.transform(val)\n",
    "test_processed = preprocessor.transform(test)\n",
    "\n",
    "config['data'] = {\n",
    "    \"train_data\": train_processed,\n",
    "    \"val_data\": val_processed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model val MAE: 0.6052235072696969\n",
      "Default model test MAE: 0.5975699190558466\n"
     ]
    }
   ],
   "source": [
    "# Default model setting\n",
    "model_name = config['model']['name']\n",
    "model = helpers.fit_model(\n",
    "    model_name,\n",
    "    train_processed['X'], train_processed['y'],\n",
    "    init_args=config['model']['init_args'],\n",
    "    fit_args=config['model']['fit_args']\n",
    ")\n",
    "val_preds = model.predict(val_processed['X'])\n",
    "val_mae = mean_absolute_error(val_preds, val_processed['y'])\n",
    "print(f'Default model val MAE: {val_mae}')\n",
    "test_preds = model.predict(test_processed['X'])\n",
    "test_mae = mean_absolute_error(test_preds, test_processed['y'])\n",
    "print(f'Default model test MAE: {test_mae}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform hyperparameter tuning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_study(config, objective_fn):\n",
    "    param_ranges = {}\n",
    "    for name, args in config['tune_params'].items():\n",
    "        param_ranges[name] = ParamRange(**args)\n",
    "    \n",
    "    tuner = HyperparamTuner(\n",
    "        objective_fn=objective_fn,\n",
    "        param_ranges=param_ranges,\n",
    "        base_config=config,\n",
    "        n_trials=config['study']['tuner_args']['n_trials']\n",
    "    )\n",
    "    final_config = tuner.optimize()\n",
    "    return tuner, final_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wod_predictor.hyperparam_search.tuner:Start hyperparameter optimization for 20 trials\n",
      "[I 2024-12-03 14:28:36,345] A new study created in memory with name: no-name-73237a10-ca08-41ad-89e7-cac43ceb5f66\n",
      "[I 2024-12-03 14:31:14,512] Trial 0 finished with value: 0.5842928553942847 and parameters: {'n_estimators': 193, 'max_depth': 29, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.5842928553942847.\n",
      "[I 2024-12-03 14:31:46,143] Trial 1 finished with value: 0.5811097780431514 and parameters: {'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.5811097780431514.\n",
      "[I 2024-12-03 14:35:35,853] Trial 2 finished with value: 0.5822721873950194 and parameters: {'n_estimators': 305, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.5811097780431514.\n",
      "[I 2024-12-03 14:38:28,440] Trial 3 finished with value: 0.5734311908622921 and parameters: {'n_estimators': 418, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5734311908622921.\n",
      "[I 2024-12-03 14:40:20,214] Trial 4 finished with value: 0.568310856199666 and parameters: {'n_estimators': 159, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.568310856199666.\n",
      "[I 2024-12-03 14:41:59,164] Trial 5 finished with value: 0.5867035426297188 and parameters: {'n_estimators': 310, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.568310856199666.\n",
      "[I 2024-12-03 14:45:05,030] Trial 6 finished with value: 0.5794042572918648 and parameters: {'n_estimators': 233, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.568310856199666.\n",
      "[I 2024-12-03 14:46:09,959] Trial 7 finished with value: 0.5959851766655735 and parameters: {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.568310856199666.\n",
      "[I 2024-12-03 14:46:42,834] Trial 8 finished with value: 0.5881157840606227 and parameters: {'n_estimators': 41, 'max_depth': 29, 'min_samples_split': 20, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.568310856199666.\n",
      "[I 2024-12-03 14:47:25,573] Trial 9 finished with value: 0.5946510114568105 and parameters: {'n_estimators': 159, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.568310856199666.\n",
      "[I 2024-12-03 14:52:09,542] Trial 10 finished with value: 0.5658510426570786 and parameters: {'n_estimators': 474, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5658510426570786.\n",
      "[I 2024-12-03 14:57:04,149] Trial 11 finished with value: 0.5657638193825143 and parameters: {'n_estimators': 469, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.5657638193825143.\n",
      "[I 2024-12-03 15:01:57,499] Trial 12 finished with value: 0.5657696488014925 and parameters: {'n_estimators': 491, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.5657638193825143.\n",
      "[I 2024-12-03 15:07:04,329] Trial 13 finished with value: 0.5648208116336085 and parameters: {'n_estimators': 488, 'max_depth': 14, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.5648208116336085.\n",
      "[I 2024-12-03 15:11:53,459] Trial 14 finished with value: 0.5680012613060623 and parameters: {'n_estimators': 414, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.5648208116336085.\n",
      "[I 2024-12-03 15:15:38,224] Trial 15 finished with value: 0.5656633045911461 and parameters: {'n_estimators': 398, 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.5648208116336085.\n",
      "[I 2024-12-03 15:18:45,005] Trial 16 finished with value: 0.5707471498603747 and parameters: {'n_estimators': 379, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.5648208116336085.\n",
      "[I 2024-12-03 15:23:24,864] Trial 17 finished with value: 0.5731957100545478 and parameters: {'n_estimators': 374, 'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.5648208116336085.\n",
      "[I 2024-12-03 15:27:22,782] Trial 18 finished with value: 0.56654323574336 and parameters: {'n_estimators': 422, 'max_depth': 12, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.5648208116336085.\n",
      "[I 2024-12-03 15:30:16,525] Trial 19 finished with value: 0.5682293771933026 and parameters: {'n_estimators': 352, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.5648208116336085.\n",
      "INFO:wod_predictor.hyperparam_search.tuner:Best score: 0.5648208116336085\n"
     ]
    }
   ],
   "source": [
    "tuner, final_config = start_study(config, model_only_objective)\n",
    "\n",
    "# Fit the model with the best parameters\n",
    "model = helpers.fit_model(\n",
    "    model_name,\n",
    "    train_processed['X'], train_processed['y'],\n",
    "    init_args=final_config['model']['init_args'],\n",
    "    fit_args=final_config['model']['fit_args']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model val MAE: 0.5649113263930734\n",
      "Best model test MAE: 0.5705556526158794\n"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict(val_processed['X'])\n",
    "val_mae = mean_absolute_error(val_preds, val_processed['y'])\n",
    "print(f'Best model val MAE: {val_mae}')\n",
    "test_preds = model.predict(test_processed['X'])\n",
    "new_test_mae = mean_absolute_error(test_preds, test_processed['y'])\n",
    "print(f'Best model test MAE: {new_test_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_change(before, after):\n",
    "    if before == 0 or after == 0:\n",
    "        raise ValueError(\"Percentage change is undefined for value 0.\")\n",
    "    return (before - after) * 2 / (before + after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 4.625% improvement after tuning hypereparamters.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {abs(100 * percentage_change(test_mae, new_test_mae)):.3f}% improvement after tuning hypereparamters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results (optional)\n",
    "import os\n",
    "\n",
    "save_path = 'modeling/kenneth/results/random_forest'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "tuner.save_best_state('modeling/kenneth/results/random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
