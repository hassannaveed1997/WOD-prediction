{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from helpers import retrieve_benchmark_info\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wod_predictor\n",
    "from wod_predictor.data_loader import DataLoader\n",
    "\n",
    "\n",
    "data_path = wod_predictor.__path__[0].replace(\"wod_predictor\", \"Data\")\n",
    "loader = DataLoader(root_path = data_path, objects= ['open_results','descriptions','benchmark_stats',  'athlete_info'])\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = data['athlete_info'].index\n",
    "newly_scraped = pd.read_csv(\"benchmark_stats_scraped.csv\")\n",
    "old_errors = pd.read_csv(\"benchmark_stats_errors.csv\")['0']\n",
    "already_scraped = data['benchmark_stats'].index.union(newly_scraped['athlete_id'])\n",
    "id_not_scraped = all_ids.difference(already_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find some priorities between the ones that have not been scraped\n",
    "less_errors = id_not_scraped.difference(old_errors)\n",
    "# ids_to_scrape = data['open_results'].loc[id_not_scraped].notna().sum(axis=1).sort_values(ascending=False).index\n",
    "ids_to_scrape = data['open_results'].loc[less_errors].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp for my testing\n",
    "ids_to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Function to scrape multiple athlete IDs in parallel\n",
    "def scrape_athletes_in_parallel(athlete_ids):\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submit the tasks and get the results\n",
    "        future_to_id = {executor.submit(retrieve_benchmark_info, athlete_id): athlete_id for athlete_id in athlete_ids}\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(future_to_id):\n",
    "            athlete_id = future_to_id[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append((athlete_id, result))\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for athlete {athlete_id}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def scrape_results_serial(athlete_ids):\n",
    "    results = []\n",
    "    for athlete_id in (athlete_ids):\n",
    "        try:\n",
    "            result = retrieve_benchmark_info(athlete_id)\n",
    "            results.append((athlete_id, result))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for athlete {athlete_id}: {e}\")\n",
    "            results.append((athlete_id, e))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results(results):\n",
    "    already_scraped = pd.read_csv(\"benchmark_stats_scraped.csv\")\n",
    "    newly_scraped = [x[1] for x in results if isinstance(x[1], dict)]\n",
    "    newly_scraped = pd.DataFrame(newly_scraped)\n",
    "\n",
    "    all_scraped = pd.concat([newly_scraped, already_scraped])\n",
    "    if all_scraped.duplicated(subset=['athlete_id']).sum() > 0:\n",
    "        print(\"Warning: Duplicates found in scraped data\")\n",
    "        all_scraped.drop_duplicates(subset=['athlete_id'], inplace=True)\n",
    "\n",
    "    old_errors = pd.read_csv(\"benchmark_stats_errors.csv\")['0']\n",
    "    new_errors = [x[0] for x in results if not isinstance(x[1], dict)]\n",
    "    new_errors = pd.Series(new_errors)\n",
    "    errors = pd.concat([new_errors, old_errors])\n",
    "\n",
    "    # print how many errors and how many successes we have\n",
    "    print(f\"Errors: {new_errors.shape[0]}\")\n",
    "    print(f\"Successes: {newly_scraped.shape[0]}\")\n",
    "    print(f\"Total scraped: {all_scraped.shape[0]}\")\n",
    "\n",
    "    all_scraped.to_csv(\"benchmark_stats_scraped.csv\", index=False)\n",
    "    errors.to_csv(\"benchmark_stats_errors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "batch_results = []\n",
    "for i in (range(0, len(ids_to_scrape), BATCH_SIZE)):\n",
    "    batch = ids_to_scrape[i:i+BATCH_SIZE]\n",
    "\n",
    "    batch_results += scrape_athletes_in_parallel(batch)\n",
    "    if i % 100 == 0:\n",
    "        save_results(batch_results)\n",
    "        batch_results = []\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wod_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
